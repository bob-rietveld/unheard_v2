# Complete Data Pipeline: Context â†’ Personas â†’ Responses â†’ Dataset â†’ AutoDS

**Date**: 2026-01-29
**Version**: 1.0
**Purpose**: End-to-end explanation of how data flows through Unheard

---

## The Complete Picture

You asked: *"How do persona conversations/surveys become a dataset for AutoDS?"*

Here's the **complete pipeline** with all pieces connected:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: CONTEXT INGESTION                                â”‚
â”‚  User uploads customer data / connects Attio CRM           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        347 real customers â†’ 20 realistic personas
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: EXPERIMENT DESIGN                                â”‚
â”‚  AI assistant generates optimal config from conversation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        Config with experiment type, hypothesis, personas
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: EXPERIMENT EXECUTION                             â”‚
â”‚  10 personas Ã— 3 rounds = 30 text responses (parallel)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        30 unstructured responses:
        "I'd pay $50 if it included analytics..."
        "Too expensive compared to competitors..."
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 4: DATASET EXTRACTION (NEW!)                        â”‚
â”‚  Transform text â†’ structured data with observability       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        Structured dataset (30 rows Ã— 15 columns):
        persona_id, name, age, role, willingness_to_pay, max_price, ...
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 5: QUALITY VALIDATION                               â”‚
â”‚  User reviews extraction quality, corrects if needed       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        Validated dataset with confidence scores
                        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 6: AUTODS DISCOVERY                                 â”‚
â”‚  MCTS explores patterns in validated dataset               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        Surprising insights discovered
```

---

## Stage-by-Stage Breakdown

### **Stage 1: Context Ingestion** (Day 1, Minute 0-2)

**What Happens**:
```typescript
// User connects Attio CRM
const attioConnector = new AttioConnector({ accessToken });
await attioConnector.authenticate();

// Fetch contacts
const contacts = await attioConnector.fetchContacts({ limit: 347 });

// Contacts look like:
[
  {
    id: "att_123",
    name: "Sarah Chen",
    email: "sarah@techcorp.com",
    jobTitle: "VP Engineering",
    company: "TechCorp",
    notes: "Interested in API automation tools. Budget: $50k/year for tools.",
    customFields: {
      company_size: "50-200",
      industry: "SaaS",
      deal_size: 15000
    }
  },
  // ... 346 more
]

// Generate personas from contacts
const personas = await personaGenerator.generateFromContext(userId, {
  count: 20,
  sourceDocuments: [crmDataId],
  diversity: 'high'
});

// Personas look like:
[
  {
    _id: "persona_1",
    name: "Sarah Chen",
    demographics: { age: 38, gender: "Female", location: "San Francisco" },
    jobRole: { title: "VP Engineering", company: "TechCorp", seniority: "VP" },
    company: { name: "TechCorp", size: "50-200", industry: "SaaS" },
    beliefs: [
      "Tools should have clear ROI",
      "API automation saves engineering time",
      "Willing to pay for quality"
    ],
    source: "crm",
    sourceId: "att_123",
    realQuote: "Budget: $50k/year for tools"  // From CRM notes
  },
  // ... 19 more diverse personas
]
```

**Result**: 20 realistic personas grounded in real customer data

---

### **Stage 2: Experiment Design** (Minute 2-3)

**What Happens**:
```typescript
// User types: "test pricing for my API at $50/mo"

// AI searches context
const context = await contextSearcher.search(userId, "pricing strategy API");
// Finds: "Q4_Strategy.pdf mentions premium tier at $50/mo"

// AI suggests template
const template = await templateMatcher.search({ query: "pricing validation API" });
// Finds: "B2B SaaS Pricing Validation"

// AI generates config
const config = {
  experiment: {
    name: "API Pricing Test - $50/mo",
    type: "survey",  // â† IMPORTANT: Determines extractor type
    hypothesis: {
      statement: "Developers will pay $50/mo for our API",
      category: "pricing"
    },
    stimulus: {
      type: "scenario",
      content: "Imagine an API that automates your background jobs. It costs $50/month. How do you feel about this pricing?"
    }
  },
  agents: {
    focusGroupId: "fg_enterprise_devs",  // 10 personas
    network: { topology: "broadcast", maxRounds: 3 }
  },
  execution: {
    llmStrategy: "local-first",
    models: { persona: "qwen2.5:32b" },
    parallelism: { maxConcurrent: 10, provider: "ollama" }
  },
  extraction: {  // NEW: Extraction config
    method: "survey",  // Use SSR extractor
    fields: [
      { name: "willingness_to_pay", type: "boolean" },
      { name: "max_price", type: "number" },
      { name: "required_features", type: "array<string>" }
    ]
  },
  discovery: {
    enabled: true,  // User wants AutoDS
    trigger: "after_experiment"
  }
};
```

**Result**: Complete config ready to execute

---

### **Stage 3: Experiment Execution** (Minute 3-3.5)

**What Happens**:
```typescript
// Experiment runner executes
const runner = new ExperimentRunner(config);
await runner.start();

// Round 1: 10 personas respond in parallel (2 seconds)
const round1Responses = await Promise.all(
  personas.map(persona =>
    tinyPersonAgent.respond(persona, config.stimulus, { round: 1 })
  )
);

// Responses look like:
[
  {
    personaId: "persona_1",
    personaName: "Sarah Chen",
    round: 1,
    response: "I think $50/mo is reasonable for a tool like this, especially if it automates our job queues. However, I'd want to see analytics and priority support included at that price point. Without those features, I'd probably only pay around $35/mo.",
    sentiment: 0.65,
    confidence: 0.88,
    reasoning: "Based on my budget constraints and value assessment"
  },
  // ... 9 more
]

// Rounds 2 and 3 execute similarly
// Total: 30 unstructured text responses
```

**Result**: 30 text responses collected, but **NO structured data yet**

**The Gap**: MCTS needs DataFrame, we have text!

---

### **Stage 4: Dataset Extraction** (Minute 3.5-4) **â† THE MISSING BRIDGE**

This is where the magic happens.

#### **Step 4.1: Select Extractor Type**

```typescript
// Determine which extractor to use
const extractorType = determineExtractorType(config.experiment.type);

// For our pricing experiment:
// experiment.type === "survey" â†’ Use SSR Extractor

const extractor = ExtractorFactory.create('survey');
```

#### **Step 4.2: SSR Extraction (for survey-type)**

```typescript
// Survey Extractor uses Semantic Similarity Rating

// 1. Define reference statements for Likert scale
const referenceStatements = {
  1: ["I would never pay this price", "This is far too expensive", "No value at all"],
  2: ["This seems expensive", "I probably won't pay", "Limited value"],
  3: ["I'm neutral about this price", "Might consider it", "Depends on features"],
  4: ["This seems reasonable", "I would probably pay", "Good value"],
  5: ["This is a great price", "I'd definitely pay", "Excellent value"]
};

// 2. Embed all responses
const responseEmbeddings = await embedder.embed(
  round1Responses.map(r => r.response)
);

// 3. Embed reference statements
const referenceEmbeddings = await embedReferences(referenceStatements);

// 4. Calculate similarity scores
for (const [responseEmb, response] of zip(responseEmbeddings, round1Responses)) {
  // Calculate cosine similarity to each Likert point
  const similarities = {
    1: cosineSimilarity(responseEmb, avg(referenceEmbeddings[1])),
    2: cosineSimilarity(responseEmb, avg(referenceEmbeddings[2])),
    3: cosineSimilarity(responseEmb, avg(referenceEmbeddings[3])),
    4: cosineSimilarity(responseEmb, avg(referenceEmbeddings[4])),
    5: cosineSimilarity(responseEmb, avg(referenceEmbeddings[5])),
  };

  // Sarah's response: "I think $50/mo is reasonable... However, I'd want analytics..."
  // Similarities: { 1: 0.12, 2: 0.24, 3: 0.31, 4: 0.68, 5: 0.42 }
  //                                           ^^^^^ Highest!

  // Normalize to probability distribution
  const distribution = normalizeProbabilities(similarities);
  // { 1: 0.05, 2: 0.10, 3: 0.15, 4: 0.48, 5: 0.22 }

  // Extract rating: mode of distribution
  const rating = 4;  // Most likely
  const confidence = 0.48;  // Probability of rating=4
}
```

#### **Step 4.3: Additional Field Extraction (LLM)**

```typescript
// For other fields (max_price, required_features), use LLM

const additionalFields = await extractAdditionalFields(responses, schema);

// For Sarah's response:
{
  max_price: 50,  // Extracted from "I think $50/mo is reasonable"
  required_features: ["analytics", "priority support"],  // Extracted from "I'd want to see..."
  conditions: ["analytics and priority support"],
  _fieldConfidence: {
    max_price: 0.95,  // High confidence (explicitly mentioned)
    required_features: 0.90,  // High confidence (explicitly mentioned)
  }
}
```

#### **Step 4.4: Combine into Dataset Record**

```typescript
// Merge persona data + SSR output + additional fields

const record = {
  // Persona attributes
  personaId: "persona_1",
  personaName: "Sarah Chen",
  age: 38,
  gender: "Female",
  jobTitle: "VP Engineering",
  company: "TechCorp",
  companySize: "50-200",
  industry: "SaaS",

  // SSR extraction
  price_acceptance_rating: 4,  // From SSR
  ssr_confidence: 0.48,
  ssr_distribution: { 1: 0.05, 2: 0.10, 3: 0.15, 4: 0.48, 5: 0.22 },

  // Additional fields
  willingness_to_pay: true,  // Derived from rating >= 4
  max_price: 50,
  required_features: ["analytics", "priority support"],

  // Metadata
  round: 1,
  sentiment: 0.65,
  confidence: 0.88,
  responseLength: 247,

  // Original response (for validation)
  responseText: "I think $50/mo is reasonable..."
};
```

#### **Step 4.5: Repeat for All 30 Responses**

```typescript
// Process all responses (batched for efficiency)
const allRecords = await extractAllRecords(allResponses, personas, schema);

// Result: 30 structured records
```

#### **Step 4.6: Create Dataset**

```typescript
const dataset = {
  experimentId: "exp_123",
  experimentName: "API Pricing Test - $50/mo",

  records: allRecords,  // 30 structured records

  csv: convertToCSV(allRecords),
  // Output:
  // personaId,name,age,jobTitle,company,companySize,price_acceptance_rating,willingness_to_pay,max_price,required_features,sentiment
  // persona_1,Sarah Chen,38,VP Engineering,TechCorp,50-200,4,true,50,"analytics;priority support",0.65
  // persona_2,Mike Johnson,42,CTO,StartupCo,10-50,2,false,35,"basic features",0.35
  // ...

  json: JSON.stringify(allRecords, null, 2),

  dataframeCode: `
import pandas as pd
import json

# Dataset from experiment: API Pricing Test
data = ${JSON.stringify(allRecords, null, 2)}

df = pd.DataFrame(data)
print(df.head())

# Available columns:
# - personaId, name, age, jobTitle, company, companySize
# - price_acceptance_rating (1-5 Likert scale)
# - willingness_to_pay (boolean)
# - max_price (number)
# - required_features (array)
# - sentiment (number)

# Example analysis:
print(df.groupby('companySize')['max_price'].mean())
print(df.groupby('jobTitle')['willingness_to_pay'].value_counts())
`,

  schema: {
    experimentType: "survey",
    fields: [
      { name: "price_acceptance_rating", type: "number", description: "1-5 Likert scale" },
      { name: "willingness_to_pay", type: "boolean", description: "Will pay at $50/mo" },
      { name: "max_price", type: "number", description: "Maximum price willing to pay" },
      { name: "required_features", type: "array<string>", description: "Must-have features" }
    ]
  },

  stats: {
    rowCount: 30,
    columnCount: 15,
    numericColumns: ["age", "price_acceptance_rating", "max_price", "sentiment"],
    categoricalColumns: ["jobTitle", "company", "companySize", "willingness_to_pay"],
    booleanColumns: ["willingness_to_pay"],
    completeness: 0.87,  // 87% of cells have data
    readyForAnalysis: true
  },

  validation: {
    valid: true,
    errors: [],
    warnings: ["Field 'required_features' is 30% null"],
    suggestions: []
  },

  extractionMetrics: {
    totalResponses: 30,
    successfulExtractions: 30,
    avgConfidence: 0.82,
    lowConfidenceCount: 2,
    extractionTimeMs: 8500,
    llmCalls: 6,  // Batched extraction
    llmCost: 0.003
  }
};
```

**Result**: Validated, structured dataset ready for analysis

---

### **Stage 5: Quality Validation & Review** (Minute 4-4.5)

**What User Sees**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Dataset Extraction Complete!                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Quality: â­â­â­â­ Good (82% confidence)                     â”‚
â”‚                                                             â”‚
â”‚  ğŸ“ˆ Extraction Summary:                                     â”‚
â”‚    âœ… 30/30 records extracted                              â”‚
â”‚    âœ… 13 fields per record                                 â”‚
â”‚    âš ï¸  2 records with confidence <60% (review recommended) â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š Field Quality:                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Field                    â”‚ Extracted â”‚ Confidence   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ price_acceptance_rating  â”‚ 100%      â”‚ 85% âœ…      â”‚  â”‚
â”‚  â”‚ willingness_to_pay       â”‚ 100%      â”‚ 90% âœ…      â”‚  â”‚
â”‚  â”‚ max_price                â”‚ 87%       â”‚ 78% âš ï¸       â”‚  â”‚
â”‚  â”‚ required_features        â”‚ 70%       â”‚ 65% âš ï¸       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â”‚  âš ï¸  Warnings:                                              â”‚
â”‚  - Field 'required_features' has 30% missing values        â”‚
â”‚  - 2 records have low confidence scores                    â”‚
â”‚                                                             â”‚
â”‚  [View Low Confidence Records] [Re-extract] [Proceed]      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User clicks "View Low Confidence Records"**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Low Confidence Records (2)                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  Record #7: Mike Johnson (Confidence: 52%)                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚  Original Response:                                         â”‚
â”‚  "Hmm, I'd need to think about it. Depends on what's      â”‚
â”‚   included I guess. We use Sidekiq now which is free."    â”‚
â”‚                                                             â”‚
â”‚  Extracted Data:                                            â”‚
â”‚    willingness_to_pay: false (confidence: 55%) âš ï¸          â”‚
â”‚    max_price: null (confidence: 10%) âŒ                    â”‚
â”‚    required_features: null (confidence: 0%) âŒ             â”‚
â”‚                                                             â”‚
â”‚  Issue: Response is ambiguous, no clear price mentioned    â”‚
â”‚                                                             â”‚
â”‚  [Accept] [Edit Manually] [Mark as "Unsure"]               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User selects**: "Mark as 'Unsure'" â†’ Record updated with `willingness_to_pay: null`

**Result**: User-validated dataset with corrections

---

### **Stage 6: AutoDS Discovery** (Minute 5-7) **â† NOW WITH REAL DATA!**

**What Happens**:

```typescript
// Initialize MCTS with validated dataset
const mcts = new MCTSEngine({
  maxIterations: 100,
  explorationConstant: 1.414,
  dataset: validatedDataset,  // â† CRITICAL: Real, structured data!
  initialHypothesis: "Explore pricing acceptance patterns"
});

// MCTS expansion phase
// Root node: "Explore pricing patterns"
//   â”œâ”€ Child 1: "Does job title affect willingness to pay?"
//   â”œâ”€ Child 2: "Does company size affect max_price?"
//   â””â”€ Child 3: "Are required_features correlated with price acceptance?"

// For Child 1 hypothesis testing:
// hypothesisGeneratorAgent creates hypothesis:
const hypothesis = "Does job title affect willingness to pay?";

// experimentPlannerAgent generates Python code:
const pythonCode = `
import pandas as pd
import json

# Load the ACTUAL dataset (extracted from experiment)
df = pd.read_json('dataset.json')

# Test hypothesis: job title vs willingness to pay
result = df.groupby('jobTitle')['willingness_to_pay'].agg(['mean', 'count'])
print(result)

# Chi-square test for independence
from scipy.stats import chi2_contingency
contingency = pd.crosstab(df['jobTitle'], df['willingness_to_pay'])
chi2, p_value, dof, expected = chi2_contingency(contingency)

output = {
  'means_by_role': result.to_dict(),
  'chi2_statistic': chi2,
  'p_value': p_value,
  'significant': p_value < 0.05
}

print(json.dumps(output))
`;

// Execute in Modal sandbox WITH THE REAL DATASET
const result = await modal.execute(pythonCode, { data: dataset.json });

// Result:
{
  means_by_role: {
    "CTO": { mean: 0.75, count: 4 },
    "VP Engineering": { mean: 0.85, count: 6 },
    "Director": { mean: 0.50, count: 3 }
  },
  chi2_statistic: 8.42,
  p_value: 0.015,
  significant: true  // â† Statistically significant!
}

// beliefElicitorAgent interprets:
const interpretation = `
VPs Engineering show highest willingness to pay (85% vs 75% for CTOs).
This is statistically significant (p=0.015).
`;

// Bayesian belief update
const beliefs = {
  prior: { alpha: 0.5, beta: 0.5 },  // Uninformed prior
  posterior: { alpha: 5.5, beta: 1.5 },  // Updated with evidence
  surprise: 0.73  // HIGH - this is surprising!
};

// MCTS marks this path as high-value
// Continues exploring...
```

#### **Stage 6 continued: More Hypotheses Tested**

```python
# Child hypothesis 2: "Does company size affect max_price?"

import pandas as pd
df = pd.read_json('dataset.json')

# Analysis
result = df.groupby('companySize')['max_price'].agg(['mean', 'median', 'std'])
print(result)

# Output:
#              mean  median   std
# companySize
# 10-50        37.5    35.0   5.2
# 50-200       51.2    50.0   7.8  â† Sweet spot!
# 200-500      68.3    70.0  12.1
```

```python
# Child hypothesis 3: "What features justify higher prices?"

import pandas as pd
df = pd.read_json('dataset.json')

# Explode required_features array
features_df = df.explode('required_features')

# Find features mentioned by high-price personas
high_price = features_df[features_df['max_price'] >= 60]
feature_counts = high_price['required_features'].value_counts()

print(feature_counts)

# Output:
# analytics: 8
# priority support: 7
# webhooks: 6
# SLA guarantees: 5
```

**After 100 iterations (1 minute)**:

```
MCTS Results:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” Discovery Findings (Surprising Patterns)               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â­â­â­â­â­ Highly Surprising (Surprise: 0.89)               â”‚
â”‚  "VPs Engineering 40% more willing to pay than CTOs"      â”‚
â”‚  â†’ Your target should be VPs, not CTOs!                    â”‚
â”‚                                                             â”‚
â”‚  â­â­â­â­ Surprising (Surprise: 0.73)                        â”‚
â”‚  "Company size 50-200 is the sweet spot for $50 pricing"   â”‚
â”‚  â†’ Smaller companies want $35, larger pay $70+             â”‚
â”‚                                                             â”‚
â”‚  â­â­â­ Moderately Surprising (Surprise: 0.61)              â”‚
â”‚  "Analytics + Priority Support required for $50+ pricing"  â”‚
â”‚  â†’ Without these, price acceptance drops to $35            â”‚
â”‚                                                             â”‚
â”‚  ğŸ’¡ Actionable Recommendation:                             â”‚
â”‚  Test tiered pricing:                                      â”‚
â”‚  - Basic: $35 (10-50 employees, basic features)            â”‚
â”‚  - Growth: $50 (50-200 employees, + analytics/support)     â”‚
â”‚  - Enterprise: $70 (200+ employees, + SLA/webhooks)        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Result**: Actionable insights backed by statistical evidence from real customer data

---

## The Complete Flow Visualized

```
DAY 1: MINUTE 0
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User opens app   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 1-2: CONTEXT
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Connect Attio CRM                         â”‚
â”‚   â†“                                      â”‚
â”‚ 347 contacts synced                      â”‚
â”‚   â†“                                      â”‚
â”‚ 20 personas generated                    â”‚
â”‚   âœ“ Grounded in real customers           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 2-3: EXPERIMENT DESIGN
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User: "test pricing at $50/mo"           â”‚
â”‚   â†“                                      â”‚
â”‚ AI: Finds template + context             â”‚
â”‚   â†“                                      â”‚
â”‚ Config generated                         â”‚
â”‚   âœ“ Experiment type: survey (SSR)        â”‚
â”‚   âœ“ Extraction fields defined            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 3-3.5: EXECUTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 10 personas Ã— 3 rounds (parallel)        â”‚
â”‚   â†“                                      â”‚
â”‚ 30 text responses:                       â”‚
â”‚ "I'd pay $50 if..."                     â”‚
â”‚ "Too expensive unless..."                â”‚
â”‚   âœ“ Unstructured conversational data     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 3.5-4: DATASET EXTRACTION â­ NEW!
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SSR Extractor processes responses        â”‚
â”‚   â†“                                      â”‚
â”‚ Step 1: Embed responses                  â”‚
â”‚ Step 2: Compare to reference statements  â”‚
â”‚ Step 3: Calculate Likert ratings         â”‚
â”‚ Step 4: Extract additional fields        â”‚
â”‚ Step 5: Validate quality                 â”‚
â”‚   â†“                                      â”‚
â”‚ Structured dataset (30 Ã— 15):            â”‚
â”‚ [persona_id, age, role, rating,          â”‚
â”‚  willingness_to_pay, max_price, ...]     â”‚
â”‚   âœ“ CSV + JSON + DataFrame code          â”‚
â”‚   âœ“ Confidence scores per field          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 4-4.5: QUALITY REVIEW
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User sees quality dashboard:             â”‚
â”‚   - 82% avg confidence âœ…                 â”‚
â”‚   - 2 low-confidence records âš ï¸           â”‚
â”‚   - Suggestions for improvement          â”‚
â”‚   â†“                                      â”‚
â”‚ User reviews, corrects, approves         â”‚
â”‚   âœ“ High-quality validated dataset       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 5-7: AUTODS DISCOVERY
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MCTS explores with REAL DATA:            â”‚
â”‚   â†“                                      â”‚
â”‚ Hypothesis: "Job title affects price?"   â”‚
â”‚   â†“                                      â”‚
â”‚ Python code:                             â”‚
â”‚ df.groupby('jobTitle')['max_price']...   â”‚
â”‚   â†“                                      â”‚
â”‚ Executes in Modal with actual dataset    â”‚
â”‚   â†“                                      â”‚
â”‚ Result: VPs pay 40% more than CTOs!      â”‚
â”‚   â†“                                      â”‚
â”‚ Surprise: 0.89 (highly unexpected!)      â”‚
â”‚   â†“                                      â”‚
â”‚ 100 iterations â†’ 5 surprising patterns   â”‚
â”‚   âœ“ Statistical evidence                 â”‚
â”‚   âœ“ Actionable recommendations           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

MINUTE 7: RESULTS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Complete insights with confidence     â”‚
â”‚                                          â”‚
â”‚ Experiment: 60% willing to pay $50/mo   â”‚
â”‚                                          â”‚
â”‚ Discovery: Target VPs in 50-200 person  â”‚
â”‚            companies, bundle analytics   â”‚
â”‚                                          â”‚
â”‚ Confidence: 85% (validated against CRM) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total time: 7 minutes from "I want to test pricing" to "Here's what to do"**

---

## Key Innovations

### **1. Multi-Extractor System**

Different experiment types need different extraction approaches:

| Experiment Type | Extractor | Method | Output | Quality Metric |
|----------------|-----------|--------|--------|----------------|
| **Survey** | SSR | Semantic similarity to references | Likert ratings | Correlation attainment >85% |
| **Focus Group** | Conversation | LLM structured extraction | Themes + categories | Field confidence >70% |
| **A/B Test** | Hybrid | SSR + LLM | Ratings + themes | Combined metrics |
| **Interview** | Conversation | LLM extraction | Qualitative codes | Extraction rate >80% |

### **2. Observability Throughout**

**Real-Time Monitoring**:
- Extraction progress (25/30 responses processed)
- Per-field confidence scores
- Quality warnings as they occur
- Cost tracking (LLM calls for extraction)

**Post-Extraction Dashboard**:
- Overall quality grade (Excellent/Good/Fair/Poor)
- Field-by-field breakdown
- Low-confidence record list
- Improvement suggestions
- Comparison to expected distributions

**Validation Before AutoDS**:
- Block AutoDS if quality poor (<50% confidence)
- Warn if marginal (50-70% confidence)
- Proceed if good (>70% confidence)

### **3. Human-in-the-Loop**

**When Low Confidence Detected**:
1. Flag specific records and fields
2. Show original response + extracted values
3. Let user Accept / Edit / Re-extract
4. Track manual corrections
5. Learn from corrections (improve extraction prompts)

**Example**:
```
Original: "Depends on what's included I guess"
Extracted: willingness_to_pay: false (confidence: 30%)

Suggestion: Mark as "unsure" or re-prompt persona for clarification
```

---

## Technical Dependencies

### **New Dependencies**

```json
{
  "dependencies": {
    // For SSR extraction
    "@openai/embeddings": "^4.0.0",
    "tiktoken": "^1.0.10",

    // For statistical validation
    "simple-statistics": "^7.8.0",  // KS test, correlation

    // Already have
    "openai": "^4.0.0"
  }
}
```

### **External Services**

| Service | Purpose | Cost |
|---------|---------|------|
| OpenAI Embeddings | SSR extraction | $0.02/1M tokens (~$0.001 per 30 responses) |
| OpenAI GPT-4o-mini | LLM extraction | $0.15/1M tokens (~$0.003 per 30 responses) |
| Modal | Python execution | $0.0001/second (~$0.01 per discovery) |

**Total extraction cost**: ~$0.01 per experiment (negligible)

---

## Updated Implementation Phases

### **Phase 4: Experiments + Dataset Extraction (Weeks 7-8)**

**Week 7: Experiment Execution**
- Experiment runner
- Network topologies
- Results storage

**Week 8: Dataset Extraction (NEW)**
1. Implement SSR extractor
   - Reference statement creation
   - Embedding + similarity calculation
   - Distribution mapping
2. Implement Conversation extractor
   - Schema inference
   - LLM-based extraction
   - Field-level confidence
3. Implement Hybrid extractor
4. Build observability layer
   - Extraction monitor
   - Quality metrics
   - Validation logic
5. Build quality dashboard UI
   - Real-time progress
   - Field-level quality table
   - Low-confidence review
6. Add human review workflow
   - Low-confidence flagging
   - Manual correction UI
   - Re-extraction with improved prompts
7. Test end-to-end:
   - Experiment â†’ Extraction â†’ Quality validation â†’ User review â†’ AutoDS

**Deliverable**: Validated datasets ready for AutoDS with full observability

---

## Updated Success Criteria

### **Dataset Extraction Quality** âœ“

- [ ] >80% average extraction confidence
- [ ] >90% field extraction rate for required fields
- [ ] SSR correlation attainment >85% (for survey experiments)
- [ ] <10% low-confidence records requiring review
- [ ] Quality dashboard shows real-time metrics
- [ ] User can review and correct low-confidence extractions
- [ ] Dataset validation prevents poor-quality data entering AutoDS
- [ ] Extraction cost <$0.01 per experiment

---

## Example: End-to-End with Real Data

### **Complete Example: Pricing Experiment**

```typescript
// ===== SETUP =====
// User connected Attio: 347 contacts â†’ 20 personas

// ===== EXPERIMENT CONFIG =====
{
  experiment: {
    name: "CloudQueue API Pricing Test",
    type: "survey",  // Triggers SSR extractor
    hypothesis: "Developers will pay $50/mo"
  },
  extraction: {
    method: "ssr",
    fields: [
      { name: "price_acceptance_rating", type: "likert-5" },
      { name: "willingness_to_pay", type: "boolean" },
      { name: "max_price", type: "number" },
      { name: "required_features", type: "array<string>" }
    ]
  }
}

// ===== EXECUTION =====
// 10 personas respond in parallel (6 seconds)

// ===== RESPONSES =====
[
  {
    persona: "Sarah (VP Eng, TechCorp)",
    response: "I think $50/mo is reasonable for API automation,
               especially with analytics and priority support.
               Without those, maybe $35/mo."
  },
  {
    persona: "Mike (CTO, StartupCo)",
    response: "Too expensive. We use Sidekiq which is free.
               I'd pay $20-25 max for managed hosting."
  },
  // ... 28 more
]

// ===== EXTRACTION (SSR) =====
// Sarah's response embedded
// Compared to references:
//   "I think $50 is reasonable..." â†’ Similarity to Likert 4: 0.68
// Extracted:
{
  price_acceptance_rating: 4,  // "Somewhat agree"
  willingness_to_pay: true,
  max_price: 50,  // Extracted via LLM
  required_features: ["analytics", "priority support"],
  ssr_confidence: 0.68,
  field_confidence: { max_price: 0.95, required_features: 0.90 }
}

// Mike's response:
{
  price_acceptance_rating: 2,  // "Disagree"
  willingness_to_pay: false,
  max_price: 25,
  required_features: ["managed hosting"],
  ssr_confidence: 0.71
}

// ===== DATASET =====
CSV (30 rows):
persona_id,name,age,role,company,company_size,rating,willingness,max_price,features,sentiment
p1,Sarah,38,VP Eng,TechCorp,50-200,4,true,50,"analytics;support",0.65
p2,Mike,42,CTO,StartupCo,10-50,2,false,25,"hosting",0.30
...

// ===== VALIDATION =====
Quality: Good (82% confidence)
- 30/30 records extracted
- 2 low-confidence (flagged for review)
- Ready for AutoDS âœ“

// ===== AUTODS =====
MCTS runs with dataset â†’
Finds: "VPs in 50-200 person companies pay most ($52 avg)"

// ===== RESULT =====
User gets actionable insight with statistical backing!
```

---

## Summary

The **complete data pipeline** now works:

1. **Context** (Attio CRM) â†’ Realistic personas
2. **Experiment** (Templates + AI) â†’ Text responses
3. **Extraction** (SSR + LLM) â†’ Structured dataset â­ **NEW**
4. **Validation** (Observability) â†’ Quality assurance â­ **NEW**
5. **AutoDS** (MCTS + Python) â†’ Surprising insights
6. **Results** (Validated) â†’ Actionable recommendations

**The Missing Bridge is Now Built**:
- 3 extractor types for different experiment styles
- Full observability with quality dashboards
- Human review for ambiguous cases
- Research-backed SSR methodology (>85% accuracy)
- Validated datasets only (no garbage into AutoDS)

**What This Enables**:
- AutoDS now works with **real, validated data**
- Statistical tests are **meaningful** (not synthetic noise)
- Insights have **confidence scores** (transparent uncertainty)
- Users see **how extraction works** (not a black box)

All requirements documents have been updated. Want me to:
1. Create UI mockups for the quality dashboard?
2. Write the production SSR extractor code?
3. Design the human review workflow in detail?
4. Update the timeline with extraction tasks?