# Unheard Engine: Complete Requirements & Build Document
## Desktop App with Intelligence Layer Architecture

**Date**: 2026-01-29
**Version**: 3.0 (UX-First Edition)
**Target Architecture**: Electron Desktop with Conversational AI + Template System

---

## Executive Summary

This document captures the complete requirements for rebuilding Unheard as a desktop application using **Electron** (Node.js + React frontend), with an **intelligence layer** that eliminates configuration complexity through conversational AI, proven templates, and automatic optimization.

**Key Architectural Innovation**:
```
User Intent (natural language)
    â†’ Intelligence Layer (AI + Templates + Optimizer)
        â†’ Optimal Execution (parallelized, cost-effective)
            â†’ Insights (10x faster)
```

**Key Architectural Decisions**:
- **Desktop Framework**: Electron (Node.js backend + Vite/React frontend)
- **Intelligence Layer**: 3-tier system (Conversation â†’ Templates â†’ Optimizer)
- **LLM Strategy**: Multi-provider with parallelization (Ollama local, Modal serverless, OpenAI/Anthropic cloud)
- **UX Philosophy**: "Describe your goal" â†’ System handles complexity
- **Data Storage**: Convex for user data + Better-SQLite3 for local tracing/cache
- **Agent Framework**: Mastra (TypeScript/Node.js) - runs natively, no bridge needed
- **Template System**: Official + community library, version-controlled configs

**Critical UX Transformation**:
- **Configuration burden**: 50+ parameters â†’ Natural language conversation
- **Execution time**: 10 minutes â†’ 30 seconds (parallelization)
- **Time to first insight**: 40 minutes â†’ 2 minutes (templates + automation)
- **Learning curve**: Steep â†’ Guided (AI assistant)

**Business Impact**:
- Non-technical users can run experiments
- Team knowledge compounds through templates
- Fast iteration enables rapid learning
- Network effects through community templates

---

## Table of Contents

1. [Core Functionalities to Retain](#1-core-functionalities-to-retain)
2. [Intelligence Layer Architecture](#2-intelligence-layer-architecture)
3. [Technical Architecture](#3-technical-architecture)
4. [Template System Design](#4-template-system-design)
5. [Enhanced Experiment Assistant](#5-enhanced-experiment-assistant)
6. [Execution Optimization](#6-execution-optimization)
7. [Implementation Roadmap (12 Weeks)](#7-implementation-roadmap-12-weeks)
8. [Data Models](#8-data-models)
9. [Success Criteria](#9-success-criteria)
10. [Questions & Decisions](#10-questions--decisions)

---

## 1. Core Functionalities to Retain

### 1.1 MCTS Engine (Monte Carlo Tree Search)

**Purpose**: Discovery of surprising market insights using Bayesian reasoning

**Key Components**:
- **Algorithm**: Four-phase MCTS (Selection, Expansion, Simulation, Backpropagation)
- **Node Selection**: UCB1 (Upper Confidence Bound) with exploration constant âˆš2
- **Reward Function**: Bayesian Surprise via KL divergence
- **Belief Model**: Beta-Bernoulli conjugate prior (Î±=0.5, Î²=0.5)
- **Progressive Widening**: Adaptive tree expansion (k Ã— visits^Î±)

**Implementation Files** (Keep in TypeScript):
- `src/lib/mcts/tree.ts` - Core tree search algorithm
- `src/lib/mcts/surprise.ts` - KL divergence and surprise calculation
- `src/lib/mcts/belief-model.ts` - Beta-Bernoulli belief updates
- `src/lib/autodiscovery/engine.ts` - Enhanced AutoDiscovery engine
- `src/lib/autodiscovery/beliefs.ts` - Advanced belief mathematics

**Mathematical Functions** (implemented locally, no jstat dependency):
- Log-gamma (Lanczos approximation)
- Beta function
- Digamma function (asymptotic expansion)
- Incomplete Beta function (continued fraction)
- Beta CDF/PDF
- Beta distribution sampling

**Input Interface**:
```typescript
interface MCTSConfig {
  maxIterations: number;           // Default: 500
  explorationConstant: number;     // Default: 1.414 (âˆš2)
  maxDepth: number;                // Default: 10
  surprisalThreshold: number;      // Default: 0.5
  progressiveWideningK: number;    // Default: 1.0
  progressiveWideningAlpha: number; // Default: 0.5
  beliefSamples?: number;          // LLM samples for belief elicitation
  rewardMode?: "belief" | "kl" | "belief_and_kl";
  parallelExpansion?: number;      // NEW: Parallel node expansion (default: 10)
  useModal?: boolean;              // Python sandbox execution
}
```

**Output Interface**:
```typescript
interface MCTSResult {
  totalNodes: number;
  bestHypothesis?: string;
  bestSurpriseScore?: number;
  bestPath: string[];
  hypotheses: HypothesisSummary[];
  stats: ExplorationStats;
}
```

### 1.2 Dataset Extraction System (NEW - CRITICAL)

**Purpose**: Transform unstructured experiment responses into structured, validated datasets for AutoDS analysis

**The Critical Gap**: Experiment responses are conversational text (*"I'd pay $50 if it included analytics"*). AutoDS expects structured data (CSV/DataFrame). The Dataset Extraction System bridges this gap.

**Three Extractor Types**:

1. **Survey Extractor** (Semantic Similarity Rating Method)
   - **Use case**: Rating/scale questions, Likert responses, NPS
   - **Method**: SSR (Semantic Similarity Rating) from arxiv:2510.08338v3
   - **Process**:
     1. Embed responses using text-embedding-3-small
     2. Compare to reference statements for each Likert point
     3. Calculate probability distribution via cosine similarity
     4. Extract rating with confidence score
   - **Validation**: KS distance <0.2, correlation attainment >85%
   - **Quality**: >90% correlation with human responses
   - **Best for**: Survey-type experiments with quantitative outputs

2. **Conversation Extractor** (LLM Structured Extraction)
   - **Use case**: Focus groups, interviews, open-ended discussions
   - **Method**: LLM-based extraction with field-level confidence tracking
   - **Process**:
     1. Infer extraction schema from conversation content
     2. Extract structured fields using GPT-4o-mini
     3. Calculate per-field confidence (mentioned in text = 0.9, inferred = 0.3)
     4. Flag low-confidence records for human review
   - **Validation**: >80% field extraction rate, >70% avg confidence
   - **Quality**: Field-level confidence scores, human review workflow
   - **Best for**: Qualitative experiments with thematic analysis

3. **Hybrid Extractor**
   - **Use case**: Mixed quantitative + qualitative experiments
   - **Method**: Combines SSR + LLM extraction
   - **Output**: Merged dataset with both ratings and themes
   - **Best for**: Complex multi-part experiments

**Observability Features** (Full transparency):
- Real-time extraction progress monitoring (UI updates per record)
- Field-level confidence scores (track which fields extracted well)
- Quality dashboard with warnings (flag issues before AutoDS)
- Low-confidence record review UI (human-in-the-loop correction)
- Extraction metrics logging (LLM calls, cost, time, success rate)
- Validation reports with improvement suggestions

**Dataset Output**:
```typescript
interface Dataset {
  experimentId: string;
  records: ExtractedRecord[];       // Structured rows
  csv: string;                      // CSV format for export
  json: string;                     // JSON format
  dataframeCode: string;            // Python DataFrame code (ready for AutoDS)
  schema: ExtractionSchema;         // Field definitions
  stats: DatasetStats;              // Row/column counts, types, variance
  validation: ValidationResult;     // Quality checks (errors, warnings, suggestions)
  extractionMethod: 'ssr' | 'llm_structured' | 'hybrid';
  extractionMetrics: ExtractionMetrics;  // Observability data
  createdAt: number;
}
```

**Implementation Files**:
- `src/extraction/ssr-extractor.ts` - Semantic Similarity Rating implementation
- `src/extraction/conversation-extractor.ts` - LLM-based extraction
- `src/extraction/hybrid-extractor.ts` - Combined approach
- `src/extraction/observability.ts` - Monitoring, metrics, validation
- `renderer/src/components/extraction/QualityDashboard.tsx` - Real-time quality UI
- `renderer/src/components/extraction/ReviewWorkflow.tsx` - Human review for low-confidence

**Integration with AutoDS**:
- Runs automatically after experiment completion
- User reviews extraction quality dashboard
- Can re-extract with improved prompts if quality poor
- Only datasets with validation.valid === true can trigger AutoDS
- Dataset saved with full provenance (method, confidence, source)

**Quality Metrics** (Research-Backed):
- **Confidence Score**: Avg probability of extracted values (expect >80%)
- **Extraction Rate**: % of fields successfully extracted (expect >90%)
- **Distributional KS**: Kolmogorov-Smirnov distance from expected (expect <0.2)
- **Correlation Attainment**: % of max achievable correlation (expect >85%)
- **Variance Check**: Numeric fields must have variance (0 = not informative)

### 1.3 Mastra Agent Framework

**Purpose**: Multi-agent persona simulation with realistic human behavior

**Agent Types**:

1. **TinyPerson Agents** (`src/mastra/agents/TinyPerson.ts`)
   - Simulated personas with demographics, personality (Big5), beliefs, behaviors
   - Response simulation with sentiment analysis
   - Configurable model (GPT-4o-mini, Qwen2.5, DeepSeek-V3)

2. **Persona Enrichment Agent** (`src/mastra/agents/PersonaEnrichmentAgent.ts`)
   - AI-driven persona generation from minimal input (company URL + job title)
   - Web scraping (Firecrawl) + search (Tavily) for context
   - Infers realistic traits, beliefs, preferences

3. **Enhanced Experiment Assistant Agent** (`src/mastra/agents/EnhancedExperimentAssistant.ts`) **â† NEW**
   - Conversational experiment design (natural language â†’ config)
   - Generates complete `UnheardExperimentConfig` from user intent
   - Asks clarifying questions intelligently
   - Suggests templates from library
   - Explains optimization choices in plain English
   - Iterative refinement through conversation

4. **Discovery Agents** (`src/mastra/agents/discovery/`)
   - `hypothesisGeneratorAgent`: Proposes testable hypotheses
   - `experimentPlannerAgent`: Creates test plans with Python code
   - `experimentAnalystAgent`: Interprets results
   - `beliefElicitorAgent`: Samples boolean beliefs for Bayesian updates
   - `summaryGeneratorAgent`: Creates human-readable summaries

**Network Topologies**:

1. **BroadcastNetwork**: All agents respond simultaneously (parallel) â† **DEFAULT**
   - Use case: Quick surveys, time-sensitive feedback
   - **Performance**: 10 personas in 2s (parallel) vs 20s (sequential)

2. **RoundRobinNetwork**: Sequential responses, agents build on prior responses
   - Use case: Focus groups, consensus building
   - **Performance**: Still benefits from batch processing per round

3. **ModeratedNetwork**: AI moderator guides discussion with follow-ups
   - Use case: Deep exploration, guided discussions
   - **Performance**: Moderator + batch persona responses

**Mastra Configuration** (`src/mastra/index.ts`):
```typescript
const mastra = new Mastra({
  agents: {
    enhancedExperimentAssistant,   // NEW
    personaEnrichmentAgent,
    // Discovery agents...
  },
  storage: new LibSQLStore({
    url: process.env.MASTRA_DB_URL || "file:./mastra.db",
  }),
  observability: {
    default: { enabled: true },
  },
});
```

**AI Provider Integration**:
- OpenAI: GPT-4o, GPT-4o-mini
- Anthropic: Claude Sonnet 4.5, Claude Opus 4.5, Claude Haiku 3.5
- Ollama: Qwen2.5 (7B/32B/72B), Llama3.3 (70B), DeepSeek-V3
- Modal: Any model via serverless deployment
- Model selection: Auto-selected by optimizer based on user intent

### 1.4 Experiment Management System

**Experiment Workflow** (Complete with Dataset Extraction):
```
User Describes Intent
    â†“
Intelligence Layer (AI Assistant + Template Matcher + Optimizer)
    â†“
Generated Config
    â†“
[User Reviews & Approves]
    â†“
Parallel Execution (10 personas Ã— 3 rounds = 30 responses)
    â†“
Dataset Extraction (NEW - CRITICAL STEP)
  - Select extractor type (Survey/Conversation/Hybrid)
  - Extract structured fields from text responses
  - Calculate field-level confidence scores
  - Validate quality (>80% confidence, >90% extraction rate)
  - Generate observability dashboard
  - Flag low-confidence records for review
  - User reviews & approves extraction
    â†“
Validated Dataset (CSV + JSON + DataFrame code)
    â†“
[Optional] AutoDS Discovery (MCTS with validated dataset)
    â†“
Real-Time Results + AI-Generated Insights
    â†“
Follow-Up Suggestions
```

**Database Schema** (Convex) - See [Section 8: Data Models](#8-data-models)

---

## 2. Intelligence Layer Architecture

### 2.1 Overview: Three-Tier System

The intelligence layer sits between the user and the execution engine, eliminating configuration complexity.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 1: CONVERSATION                     â”‚
â”‚   Enhanced Experiment Assistant (Mastra Agent)              â”‚
â”‚   - Takes natural language input                            â”‚
â”‚   - Asks clarifying questions                               â”‚
â”‚   - Generates complete configs                              â”‚
â”‚   - Suggests templates                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 2: TEMPLATES                        â”‚
â”‚   Template Library (Official + Community)                   â”‚
â”‚   - Pre-optimized configs                                   â”‚
â”‚   - Version controlled                                      â”‚
â”‚   - Shareable                                               â”‚
â”‚   - Forkable                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIER 3: OPTIMIZER                        â”‚
â”‚   Execution Optimizer                                       â”‚
â”‚   - Selects best LLM provider                               â”‚
â”‚   - Sets parallelism limits                                 â”‚
â”‚   - Estimates cost/time                                     â”‚
â”‚   - Explains choices                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EXECUTION ENGINE                         â”‚
â”‚   Parallel LLM calls + MCTS + Mastra agents                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Design Principles

1. **Conversation Over Configuration**
   - User describes goal in natural language
   - System asks questions, not for parameters
   - Technical details hidden by default, accessible if needed

2. **Templates as Starting Points**
   - Official templates for common use cases
   - Community templates for specific industries
   - Every experiment becomes a potential template

3. **Intelligent Defaults**
   - System picks optimal execution strategy
   - User can override with simple intent ("fast", "quality", "cheap")
   - Transparent explanations for all choices

4. **Progressive Disclosure**
   - Simple flow for 80% of users
   - Advanced options available but not required
   - Power users can edit configs directly

### 2.3 User Flows

#### **Flow 1: First-Time User (Template-First)**

```
1. User opens app â†’ "What do you want to learn?"
   Search bar + template categories

2. User types: "pricing" or clicks "Pricing" category
   â†’ Shows "B2B SaaS Pricing Validation" template

3. Template customizer: 3 simple fields
   "Product Name: [____]"
   "Price Point: [$___]"
   "Target Personas: [Select from library]"

4. System shows preview:
   "I'll test your $50 pricing with 10 B2B CTOs
    Using local AI (free, 10 seconds)
    [Run Experiment]"

5. User clicks Run â†’ Experiment executes
   Live progress: "Sarah: '$50 seems reasonable but...'"

6. Results appear in 30 seconds:
   "60% positive sentiment
    Key insight: Bootstrapped founders want $35"

7. AI suggests next step:
   "Want to test tiered pricing? ($35 basic, $50 premium)"

8. User clicks "Yes" â†’ New experiment queued with updated config
```

**Time to first insight: 2 minutes** (was: 40 minutes)

#### **Flow 2: Power User (Conversation-First)**

```
1. User clicks "Start Conversation with AI"

2. User: "I want to explore why churn is high in Q3"

3. AI: "Let me help you design a discovery experiment.
   Do you have specific hypotheses, or want open-ended exploration?"

4. User: "Open-ended"

5. AI: "I'll run MCTS discovery with your churned customer personas.
   Found your 'Q3 Churned Users' persona group (23 personas)
   Using GPT-4o for quality discovery.

   Estimated: 2 minutes, $0.50

   [Show Config] [Adjust] [Run]"

6. User clicks Run â†’ Discovery executes

7. Discovery finds: "Churn spikes when billing exceeds $500/mo"

8. AI: "Want to test:
   A) Payment plans?
   B) Billing caps?
   C) Usage alerts?"

9. User: "B - billing caps"

10. AI generates new config â†’ Experiment runs
```

**Time to insight: 5 minutes** (including deep discovery)

#### **Flow 3: Team Collaboration (Template Sharing)**

```
1. User A creates successful pricing experiment
   Results show clear insights

2. User A: "Save as template"
   â†’ Name: "DevTools Pricing Test"
   â†’ Share: Team only / Public

3. User B (same company) opens app
   â†’ Sees "Recent team templates"
   â†’ "DevTools Pricing Test" by User A (â­ 5.0, used 23x)

4. User B: Click template
   â†’ Pre-filled with company personas
   â†’ Changes product name
   â†’ Runs in 10 seconds

5. Results saved to team workspace
   â†’ Both can compare pricing tests over time
   â†’ Template improves with usage data
```

**Benefit: Institutional knowledge compounds**

---

## 3. Technical Architecture

### 3.1 Technology Stack

| Layer | Technology | Rationale |
|-------|-----------|-----------|
| **Desktop Framework** | Electron | Node.js runtime, Mastra runs natively |
| **Frontend** | Vite + React 18 | Fast dev, smaller bundle than Next.js |
| **Routing** | React Router v6 | Replace Next.js App Router |
| **Main Process** | Node.js + TypeScript | Native Mastra, MCTS, LLM orchestration |
| **Intelligence Layer** | Mastra Agent (GPT-4o) | Conversational config generation |
| **Agent Framework** | Mastra (native!) | No bridge needed - runs in main process |
| **LLM Providers** | Multi-provider | Ollama, Modal, OpenAI, Anthropic |
| **Database (Cloud)** | Convex | Real-time sync, templates, experiments |
| **Database (Local)** | Better-SQLite3 | Tracing, cache, offline data |
| **Auth** | Clerk JWT | Store token in OS keychain (via keytar) |
| **UI Components** | shadcn/ui | Keep existing components |
| **Styling** | Tailwind CSS | Keep existing styles |

### 3.2 Directory Structure

```
unheard-desktop/
â”œâ”€â”€ src/                           # Electron main process (Node.js)
â”‚   â”œâ”€â”€ main.ts                    # Electron entry point
â”‚   â”œâ”€â”€ preload.ts                 # IPC bridge (contextBridge)
â”‚   â”‚
â”‚   â”œâ”€â”€ intelligence/              # NEW: Intelligence Layer
â”‚   â”‚   â”œâ”€â”€ conversation-manager.ts  # Conversation state management
â”‚   â”‚   â”œâ”€â”€ template-matcher.ts      # Template recommendation
â”‚   â”‚   â”œâ”€â”€ execution-optimizer.ts   # Auto-optimization
â”‚   â”‚   â””â”€â”€ intent-parser.ts         # Parse user intent
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                    # Config management
â”‚   â”‚   â”œâ”€â”€ manager.ts             # File I/O, validation
â”‚   â”‚   â”œâ”€â”€ validator.ts           # Zod schema validation
â”‚   â”‚   â””â”€â”€ schema.ts              # TypeScript types
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/                       # LLM orchestration layer
â”‚   â”‚   â”œâ”€â”€ orchestrator.ts        # Provider selection, routing
â”‚   â”‚   â”œâ”€â”€ worker-pool.ts         # Local parallel execution
â”‚   â”‚   â”œâ”€â”€ rate-limiter.ts        # Concurrency control
â”‚   â”‚   â”œâ”€â”€ cost-tracker.ts        # Usage & cost tracking
â”‚   â”‚   â””â”€â”€ providers/
â”‚   â”‚       â”œâ”€â”€ base.ts            # Provider interface
â”‚   â”‚       â”œâ”€â”€ openai.ts          # OpenAI provider
â”‚   â”‚       â”œâ”€â”€ anthropic.ts       # Anthropic provider
â”‚   â”‚       â”œâ”€â”€ ollama.ts          # Ollama local models
â”‚   â”‚       â””â”€â”€ modal.ts           # Modal serverless
â”‚   â”‚
â”‚   â”œâ”€â”€ orchestration/             # Experiment execution
â”‚   â”‚   â”œâ”€â”€ experiment-runner.ts   # Parallel experiment execution
â”‚   â”‚   â”œâ”€â”€ discovery-runner.ts    # Parallel MCTS
â”‚   â”‚   â””â”€â”€ scheduler.ts           # Multi-experiment scheduling
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/                # NEW: Dataset Extraction System
â”‚   â”‚   â”œâ”€â”€ extractor-factory.ts   # Select appropriate extractor
â”‚   â”‚   â”œâ”€â”€ ssr-extractor.ts       # Semantic Similarity Rating
â”‚   â”‚   â”œâ”€â”€ conversation-extractor.ts  # LLM structured extraction
â”‚   â”‚   â”œâ”€â”€ hybrid-extractor.ts    # Combined approach
â”‚   â”‚   â”œâ”€â”€ observability.ts       # Metrics, monitoring, validation
â”‚   â”‚   â”œâ”€â”€ schema-inference.ts    # Infer extraction schema
â”‚   â”‚   â””â”€â”€ validation.ts          # Quality validation
â”‚   â”‚
â”‚   â”œâ”€â”€ mcts/                      # MCTS engine (Keep TypeScript!)
â”‚   â”‚   â”œâ”€â”€ tree.ts                # Core tree search
â”‚   â”‚   â”œâ”€â”€ surprise.ts            # KL divergence
â”‚   â”‚   â”œâ”€â”€ beliefs.ts             # Beta-Bernoulli
â”‚   â”‚   â””â”€â”€ parallel-expansion.ts  # Parallel node expansion
â”‚   â”‚
â”‚   â”œâ”€â”€ mastra/                    # Mastra integration (Native!)
â”‚   â”‚   â”œâ”€â”€ index.ts               # Mastra initialization
â”‚   â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”‚   â”œâ”€â”€ EnhancedExperimentAssistant.ts  # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ TinyPerson.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ PersonaEnrichmentAgent.ts
â”‚   â”‚   â”‚   â””â”€â”€ discovery/
â”‚   â”‚   â””â”€â”€ networks/
â”‚   â”‚       â”œâ”€â”€ BroadcastNetwork.ts
â”‚   â”‚       â”œâ”€â”€ RoundRobinNetwork.ts
â”‚   â”‚       â””â”€â”€ ModeratedNetwork.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ templates/                 # NEW: Template system
â”‚   â”‚   â”œâ”€â”€ manager.ts             # Template CRUD
â”‚   â”‚   â”œâ”€â”€ official-templates.ts  # Bundled templates
â”‚   â”‚   â”œâ”€â”€ validator.ts           # Template validation
â”‚   â”‚   â””â”€â”€ versioning.ts          # Version control
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/                   # Local storage
â”‚   â”‚   â”œâ”€â”€ local-db.ts            # Better-SQLite3 wrapper
â”‚   â”‚   â”œâ”€â”€ keychain.ts            # OS keychain (keytar)
â”‚   â”‚   â””â”€â”€ cache.ts               # Results cache
â”‚   â”‚
â”‚   â”œâ”€â”€ ipc/                       # IPC handlers
â”‚   â”‚   â”œâ”€â”€ experiments.ts         # Experiment IPC
â”‚   â”‚   â”œâ”€â”€ discovery.ts           # Discovery IPC
â”‚   â”‚   â”œâ”€â”€ config.ts              # Config IPC
â”‚   â”‚   â”œâ”€â”€ templates.ts           # NEW: Template IPC
â”‚   â”‚   â”œâ”€â”€ conversation.ts        # NEW: AI conversation IPC
â”‚   â”‚   â””â”€â”€ personas.ts            # Persona IPC
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.ts
â”‚       â””â”€â”€ errors.ts
â”‚
â”œâ”€â”€ renderer/                      # Frontend (Vite + React)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.tsx               # Entry point
â”‚   â”‚   â”œâ”€â”€ App.tsx                # Root with React Router
â”‚   â”‚   â”œâ”€â”€ router.tsx             # Route definitions
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/                 # NEW: Page-level routes
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.tsx           # Template library + quick start
â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationPage.tsx  # AI assistant chat
â”‚   â”‚   â”‚   â”œâ”€â”€ TemplateLibrary.tsx   # Browse/search templates
â”‚   â”‚   â”‚   â”œâ”€â”€ ExperimentPage.tsx    # Run experiment
â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsPage.tsx       # View results
â”‚   â”‚   â”‚   â””â”€â”€ SettingsPage.tsx      # Settings
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/            # Existing + new components
â”‚   â”‚   â”‚   â”œâ”€â”€ intelligence/      # NEW
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConversationChat.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TemplateCard.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ TemplateCustomizer.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ IntentSelector.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OptimizationPreview.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction/       # NEW: Dataset Extraction UI
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ExtractionMonitor.tsx    # Real-time progress
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ QualityDashboard.tsx     # Quality metrics display
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ReviewWorkflow.tsx       # Review low-confidence
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DatasetPreview.tsx       # Preview extracted data
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ FieldConfidenceTable.tsx # Per-field quality
â”‚   â”‚   â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ExperimentWizard.tsx
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ExperimentProgress.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ResultsDashboard.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ personas/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ PersonaForm.tsx
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ PersonaSelector.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ focus-groups/
â”‚   â”‚   â”‚   â”œâ”€â”€ discovery/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ DiscoveryProgress.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ui/                # shadcn/ui
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/              # API layer
â”‚   â”‚   â”‚   â”œâ”€â”€ electron-api.ts    # IPC wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ convex-client.ts   # Convex wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ template-service.ts  # NEW
â”‚   â”‚   â”‚   â””â”€â”€ conversation-service.ts  # NEW
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ stores/                # State management (Zustand)
â”‚   â”‚   â”‚   â”œâ”€â”€ auth-store.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ template-store.ts  # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ conversation-store.ts  # NEW
â”‚   â”‚   â”‚   â”œâ”€â”€ experiment-store.ts
â”‚   â”‚   â”‚   â””â”€â”€ settings-store.ts
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ lib/                   # Utilities
â”‚   â”‚       â”œâ”€â”€ utils.ts
â”‚   â”‚       â””â”€â”€ cn.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ shared/                        # Shared types (TypeScript)
â”‚   â””â”€â”€ types/
â”‚       â”œâ”€â”€ config.ts              # Config schemas
â”‚       â”œâ”€â”€ template.ts            # NEW: Template types
â”‚       â”œâ”€â”€ conversation.ts        # NEW: Conversation types
â”‚       â”œâ”€â”€ experiment.ts          # Experiment types
â”‚       â”œâ”€â”€ persona.ts             # Persona types
â”‚       â””â”€â”€ llm.ts                 # LLM provider types
â”‚
â”œâ”€â”€ convex/                        # Convex backend
â”‚   â”œâ”€â”€ schema.ts                  # Updated with template tables
â”‚   â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ templates/                 # NEW
â”‚   â”œâ”€â”€ conversations/             # NEW
â”‚   â”œâ”€â”€ personas/
â”‚   â”œâ”€â”€ focusGroups/
â”‚   â””â”€â”€ discovery/
â”‚
â”œâ”€â”€ package.json                   # Root workspace
â”œâ”€â”€ electron-builder.json          # Build config
â””â”€â”€ README.md
```

### 3.3 LLM Parallelization Strategy

**Problem**: Sequential LLM calls create 10+ minute waits

**Solution**: Three-tier parallelization (see original plan for details)

**Performance Impact**:

| Scenario | Sequential | Parallelized | Improvement |
|----------|-----------|--------------|-------------|
| 10 personas, 3 rounds | 60s | 6s | **10x faster** |
| 50 personas, 1 round | 100s | 5s | **20x faster** |
| 100-iter MCTS | 600s (10min) | 60s (1min) | **10x faster** |

### 3.4 Communication Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Renderer Process (React + Vite)            â”‚
â”‚          - Template Library UI                      â”‚
â”‚          - Conversation Chat                        â”‚
â”‚          - Experiment Progress                      â”‚
â”‚          - Convex Client (direct WebSocket)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â”‚ IPC (contextBridge)
                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Main Process (Node.js)                     â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Intelligence Layer                   â”‚    â”‚
â”‚  â”‚  - Enhanced Assistant Agent               â”‚    â”‚
â”‚  â”‚  - Template Matcher                       â”‚    â”‚
â”‚  â”‚  - Execution Optimizer                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚          â”‚           â”‚            â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚      LLM Orchestrator                 â”‚        â”‚
â”‚  â”‚  - Provider selection                 â”‚        â”‚
â”‚  â”‚  - Rate limiting                      â”‚        â”‚
â”‚  â”‚  - Cost tracking                      â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚          â”‚           â”‚            â”‚                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  Worker   â”‚  â”‚ Modal  â”‚  â”‚  OpenAI   â”‚        â”‚
â”‚  â”‚   Pool    â”‚  â”‚Providerâ”‚  â”‚ Provider  â”‚        â”‚
â”‚  â”‚(Ollama)   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      Mastra (Native!)                     â”‚    â”‚
â”‚  â”‚  - Enhanced Assistant                     â”‚    â”‚
â”‚  â”‚  - TinyPerson agents                      â”‚    â”‚
â”‚  â”‚  - Discovery agents                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚      MCTS Engine (TypeScript)             â”‚    â”‚
â”‚  â”‚  - Parallel node expansion                â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Convex (Cloud)       â”‚
         â”‚   - Templates          â”‚
         â”‚   - Experiments        â”‚
         â”‚   - Conversations      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Template System Design

### 4.1 Template Architecture

See [Detailed Data Models Document](#task-2) for complete schemas.

**Core Concept**: Every experiment is a config. Successful configs become templates.

**Template Lifecycle**:
```
1. User creates experiment (via assistant or wizard)
2. Experiment succeeds â†’ Results validated
3. User saves as template
4. Template added to personal library
5. User shares template (team/public)
6. Other users discover and fork template
7. Fork becomes new template â†’ Cycle continues
```

**Template Types**:

1. **Official Templates** (Verified âœ“)
   - Created by Unheard team
   - Pre-optimized for common use cases
   - Guaranteed to work
   - Shipped with app

2. **Team Templates** (Internal ğŸ‘¥)
   - Created by team members
   - Shared within workspace
   - Can be private or team-visible
   - Build institutional knowledge

3. **Community Templates** (Public ğŸŒ)
   - Shared by users publicly
   - Rated and reviewed
   - Can be forked and modified
   - Network effects

### 4.2 Official Templates (Starter Set)

**Ship with V1: 5 Core Templates**

1. **B2B SaaS Pricing Validation**
   - Category: Pricing
   - Use case: Test price point acceptance
   - Variables: Product name, price, competitors
   - Optimized for: Speed + Cost (Ollama local)
   - Estimated: 10 seconds, $0

2. **Feature Prioritization Survey**
   - Category: Feature Validation
   - Use case: Rank features by customer value
   - Variables: Feature list, criteria
   - Optimized for: Broad feedback (Broadcast network)
   - Estimated: 15 seconds, $0

3. **Marketing Message Testing**
   - Category: Messaging
   - Use case: A/B test value propositions
   - Variables: Message variants (2-5)
   - Optimized for: Quick comparison
   - Estimated: 10 seconds, $0

4. **Competitive Positioning Analysis**
   - Category: Competitive Analysis
   - Use case: Compare vs competitors
   - Variables: Competitor list, differentiators
   - Optimized for: Quality (RoundRobin discussion)
   - Estimated: 30 seconds, $0.05

5. **Open-Ended Market Discovery**
   - Category: Discovery
   - Use case: Explore market with MCTS
   - Variables: Market area, initial hypotheses
   - Optimized for: Deep insights (MCTS + GPT-4o)
   - Estimated: 2 minutes, $0.50

### 4.3 Template Variables

**Purpose**: Make templates reusable by parameterizing key values

**Example**: Pricing Template
```typescript
{
  name: "B2B SaaS Pricing Validation",
  config: {
    experiment: {
      name: "{{productName}} Pricing Test",  // Variable
      context: {
        productName: "{{productName}}",      // Variable
        pricing: "{{pricePoint}}",           // Variable
        competitors: "{{competitors}}",      // Variable
      },
      stimulus: {
        content: "Imagine {{productName}} costs {{pricePoint}}/month..."
      }
    },
    agents: {
      focusGroupId: "{{targetPersonas}}"     // Variable
    }
  },
  variables: [
    {
      key: "productName",
      label: "Product Name",
      type: "text",
      required: true,
      placeholder: "e.g., Slack, Notion, Figma"
    },
    {
      key: "pricePoint",
      label: "Price Point",
      type: "number",
      required: true,
      placeholder: "e.g., 50, 99, 199"
    },
    {
      key: "competitors",
      label: "Competitors (comma-separated)",
      type: "text",
      required: false,
      placeholder: "e.g., Microsoft Teams, Discord"
    },
    {
      key: "targetPersonas",
      label: "Target Personas",
      type: "focusGroup",  // Special type: dropdown of user's focus groups
      required: true
    }
  ]
}
```

### 4.4 Template Discovery & Search

**Search Strategy**:

1. **Semantic Search** (primary)
   - User types: "test messaging"
   - System searches: name, description, solves[], tags[]
   - Returns: "Marketing Message Testing" template

2. **Category Browse**
   - User clicks: "Pricing" category
   - Shows all pricing templates sorted by usage

3. **AI Recommendation** (via Enhanced Assistant)
   - User describes goal
   - Assistant suggests best matching template
   - "Based on your goal, try 'B2B SaaS Pricing Validation'"

4. **Trending/Popular**
   - Most used this week
   - Highest rated
   - Recently added

### 4.5 Template Versioning & Forking

**Version Control**:
```typescript
{
  templateId: "abc123",
  version: "1.2.0",
  parentTemplateId: "xyz789",  // If forked
  changelog: [
    {
      version: "1.2.0",
      changes: "Added competitor comparison",
      author: "user456",
      date: "2026-01-15"
    },
    {
      version: "1.1.0",
      changes: "Optimized for Ollama",
      author: "user123",
      date: "2026-01-10"
    }
  ]
}
```

**Forking Flow**:
```
1. User finds template they like
2. Clicks "Fork" or "Customize"
3. Template copied with parentTemplateId reference
4. User modifies variables/config
5. User saves as new template
6. New template appears in their library
7. Optionally share back to community
```

**Benefits**:
- Templates improve over time
- Attribution preserved
- Users build on each other's work
- Network effects

---

## 5. Enhanced Experiment Assistant

See [Detailed Agent Spec Document](#task-3) for complete implementation.

### 5.1 Core Capabilities

**What it does**:
1. Understands user intent from natural language
2. Asks clarifying questions intelligently
3. Searches template library for matches
4. Generates complete, valid configs
5. Explains optimization choices
6. Iterates based on user feedback
7. Suggests follow-up experiments

**What makes it "enhanced"**:
- **Context-aware**: Knows user's personas, past experiments, templates
- **Template-first**: Always tries to match/fork existing template
- **Optimizer-integrated**: Uses Execution Optimizer for smart defaults
- **Cost-conscious**: Shows cost estimates, suggests cheaper alternatives
- **Iterative**: Multi-turn conversations, not single-shot generation

### 5.2 Agent Architecture

```typescript
const EnhancedExperimentAssistant = new Agent({
  name: 'enhanced-experiment-assistant',
  instructions: `[See detailed spec document]`,
  model: { provider: 'openai', model: 'gpt-4o' },
  tools: [
    searchTemplateLibraryTool,
    getUserPersonasTool,
    getUserFocusGroupsTool,
    validateConfigTool,
    estimateCostTool,
    optimizeExecutionTool,
    getTemplateDetailsTool,
    forkTemplateTool,
  ],
});
```

### 5.3 Conversation Flow Example

```
User: "I want to test if developers will pay $50/mo for my API"